---
title: "Design of Experiment and Analysis of Variance"
subtitle: "Repetition"
author: "Raju Rimal"
date: "`r format(Sys.Date(), '%d %b, %Y')`"
output:
  xaringan::moon_reader:
    includes:
      in_header: "header.html"
      after_body: "footer.html"
    lib_dir: libs
    chakra: 'libs/remark-latest.min.js'
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, 
        digits = 3, scipen = 9, signif = 999)
knitr::opts_chunk$set(echo = FALSE, comment = NULL)
library(mixlm)
library(tidyverse)
library(gganimate)
```
```{r load-function, include=FALSE}
get_fplot <- function(alpha, deg.freedom, max_limit, fvalue = NULL) {
d <- deg.freedom
lmt <- max_limit
plt <- ggplot(data.frame(x = 0:lmt), aes(x)) +
  stat_function(fun = df, args = list(df1 = d[1], df2 = d[2]), n = 200) +
  stat_function(fun = df, args = list(df1 = d[1], df2 = d[2]), n = 200, 
                xlim = c(qf(alpha, df1 = d[1], df2 = d[2], lower.tail = FALSE), lmt), 
                geom = "area") +
  ggtitle(paste("F-distribution with", paste(d, collapse = " and "), "df"),
          paste(alpha, "level of significance")) +
  labs(x = "F", y = NULL) +
  annotate(x = qf(alpha, df1 = d[1], df2 = d[2], lower.tail = FALSE),
           color = "red",
           ymin = 0, ymax = 0.1, geom = "linerange") +
  annotate(x = qf(alpha, df1 = d[1], df2 = d[2], lower.tail = FALSE),
           label = paste("F =", round(qf(alpha, df1 = d[1], df2 = d[2], lower.tail = FALSE), 3)), 
           geom = "text", y = 0.15, hjust = 0)
if (!is.null(fvalue)){
  plt <- plt +
    annotate(x = fvalue, y = 0, geom = "point", color = "red") +
    annotate(x = fvalue, y = 0, geom = "text", label = paste("F0:", round(fvalue, 3)), hjust = 1.2)
}
return(plt)
}
get_chisq_plot <- function(alpha, deg.freedom, max_limit, test_statistic = NULL){
d <- deg.freedom
lmt <- max_limit
plt <- ggplot(data.frame(x = 0:lmt), aes(x)) +
  stat_function(fun = dchisq, args = list(df = d), n = 200) +
  stat_function(fun = dchisq, args = list(df = d), n = 200, 
                xlim = c(0, qchisq(alpha, df = d, lower.tail = TRUE)), 
                geom = "area") +
  stat_function(fun = dchisq, args = list(df = d), n = 200, 
                xlim = c(qchisq(alpha, df = d, lower.tail = FALSE), lmt), 
                geom = "area") +
  ggtitle(paste("Chisq-distribution with", d, "df"),
          paste(2*alpha, "level of significance")) +
  labs(x = "Chisq", y = NULL) +
  annotate(x = c(qchisq(alpha, df = d, lower.tail = FALSE),
                 qchisq(alpha, df = d, lower.tail = TRUE)),
           color = "red",
           ymin = 0, ymax = c(0.02, 0.05), geom = "linerange") +
  annotate(x = c(qchisq(alpha, df = d, lower.tail = FALSE),
                 qchisq(alpha, df = d, lower.tail = TRUE)),
           label = paste("Chisq =", round(c(
             qchisq(alpha, df = d, lower.tail = FALSE),
             qchisq(alpha, df = d, lower.tail = TRUE)
           ), 3)), 
           geom = "text", y = c(0.02, 0.05), hjust = c(0, 1))
if (!is.null(test_statistic)){
  plt <- plt +
    annotate(x = test_statistic, y = 0, geom = "point", color = "red") +
    annotate(x = test_statistic, y = 0, geom = "text", label = paste("Chisq0:", round(test_statistic, 3)), hjust = 1.2)
}
return(plt)
}
get_tplot <- function(alpha, deg.freedom, max_limit, test_statistic = NULL){
d <- deg.freedom
lmt <- max_limit
plt <- ggplot(data.frame(x = -lmt:lmt), aes(x)) +
  stat_function(fun = dt, args = list(df = d), n = 200) +
  stat_function(fun = dt, args = list(df = d), n = 200, 
                xlim = c(-lmt, qt(alpha, df = d, lower.tail = TRUE)), 
                geom = "area") +
  stat_function(fun = dt, args = list(df = d), n = 200, 
                xlim = c(qt(alpha, df = d, lower.tail = FALSE), lmt), 
                geom = "area") +
  ggtitle(paste("T-distribution with", d, "df"),
          paste(2*alpha, "level of significance")) +
  labs(x = "T", y = NULL) +
  annotate(x = c(qt(alpha, df = d, lower.tail = FALSE),
                 qt(alpha, df = d, lower.tail = TRUE)),
           color = "red",
           ymin = 0, ymax = 0.1, geom = "linerange") +
  annotate(x = c(qt(alpha, df = d, lower.tail = FALSE),
                 qt(alpha, df = d, lower.tail = TRUE)),
           label = paste("t=", round(c(
             qt(alpha, df = d, lower.tail = FALSE),
             qt(alpha, df = d, lower.tail = TRUE)
           ), 3)), 
           geom = "text", y = 0.1, hjust = c(0, 1))
if (!is.null(test_statistic)){
  plt <- plt +
    annotate(x = test_statistic, y = 0, geom = "point", color = "red") +
    annotate(x = test_statistic, y = 0, geom = "text", 
             label = paste("t0:", round(test_statistic, 3)), 
             hjust = if(length(test_statistic) == 1) 1.2 else c(1, 0))
}
return(plt)
}
```


background-image: url(https://www.nmbu.no/sites/all/themes/nmbu_university/images/logo-nb.png)

???

Image credit: [NMBU](https://www.nmbu.no/sites/all/themes/nmbu_university/images/logo-nb.png)


---
class: center, middle, inverse

# ANOVA Model
```{r}
load("_data/Exam2013.RData")
```
```{r, fig.width=3, out.width='90%', fig.asp = 1, fig.retina=2}
bwt_plot <- x2013 %>% 
  ggplot(aes(Weight1, Weight2)) +
  geom_boxplot() +
  geom_point(fill = "grey", shape = 21) +
  stat_summary(fun.y = mean, geom = "point", shape = 15, color = "red", size = 3) +
  coord_flip() +
  labs(x = "Weight of First Child", y = 'Weight of Second Child') +
  theme(axis.text.y.left = element_text(angle = 90, hjust = 0.5)) +
  stat_summary(aes(x = 2), fun.y = mean, 
               geom = "point", shape = 15, color = "blue", size = 3)
```
---

.left-column[
# ANOVA Model
## ANOVA table

```{r, fig.width=3, out.width='90%', fig.asp = 0.9, fig.retina=2}
bwt_plot + ggtitle("Data from Exam 2013")
```

```{r}
mdl <- lm(Weight2~Weight1, data = x2013)
aov_tbl <- anova(mdl)
aov_tbl[, 1:4]
```
]
.right-column[

.left-40-column[
#### Hypothesis

\begin{aligned}
H_0: \tau_i &= 0 \text{ for i = 1, 2, 3} \\
H_1: \tau_i &\ne 0 \text{ for at least one }i
\end{aligned}

#### Decision
From <a href="images/F005-2.png" data-fancybox>F-table</a>, $F_0 > F_c$. So we reject $H_0$ at 95% confidence level.

]
.right-60-column[
```{r, fig.width = 4, out.width = '90%', fig.asp = 0.75, fig.retina = 2, fig.align = "right"}
wt <- `names<-`(reshape2::dcast(x2013, Weight1~., fun.aggregate = list, value.var = "Weight2"), c("Weight1", "Weight2"))
wt_sumry <- wt %>% 
    group_by(Weight1) %>% 
    summarize(
        mean = map_dbl(Weight2, mean),
        var = map_dbl(Weight2, var),
        n = map_dbl(Weight2, length)
    )

get_fplot(0.05, c(aov_tbl[1, 1], aov_tbl[2, 1]), 15, aov_tbl[1, 4]) +
    annotate(geom = "text", 
      x = Inf, y = Inf, 
      label = paste(capture.output(as.data.frame(wt_sumry)), 
      collapse = "\n"), 
      hjust = 1, vjust = 1,
      family = "mono")
```
]

### Questions
a) What is the 95% **confidence interval of error variance**?

b) We found that there is significant effect of first child's weight on second child, but how different is the effect of `High` from `low` and `medium`?

]

---

.left-column[
# ANOVA Model
## Confidence Interval
```{r, fig.width=3.5, out.width='90%', fig.asp = 0.9, fig.retina=2}
get_chisq_plot(0.025, 21, 50)
```
```{r, fig.width=3.5, out.width='90%', fig.asp = 0.3, fig.retina=2}
cq <- qchisq(c(0.025, 0.975), 
             aov_tbl["Residuals", "Df"], 
             lower.tail = FALSE)
ci_sigmasq <- aov_tbl["Residuals", "Sum Sq"]/cq
dta <- data.frame(y = 0, x = ci_sigmasq, estimate = aov_tbl["Residuals", "Mean Sq"])
sigma_interval <- ggplot(dta, aes(x, y)) +
  theme_void() +
  geom_point(shape = "|", size = 5) +
  geom_text(aes(label = round(x)), vjust = -2, hjust = c(0, 1)) +
  geom_point(aes(x = estimate), color = "red", size = 3) +
  geom_hline(yintercept = 0) +
  geom_text(aes(label = round(estimate), x = estimate), 
            vjust = -2, color = "red") +
  annotate(geom = "text", y = 0, vjust = 2, hjust = c(0, 1, 0.5),
           label = c("lower", "upper", "estimate"), 
           x = c(dta$x, dta$estimate[1]))
plot(sigma_interval)
```
]
.right-column[
### Confidence interval of error variance
$$\dfrac{\text{SSE}}{\chi^2_{\alpha/2, N-a}} 
\le \sigma^2 \le
\dfrac{\text{SSE}}{\chi^2_{1-(\alpha/2), N-a}}$$

### Exam 2013 Data
Using values in previous slide in above formula,
$$\left[
\dfrac{`r aov_tbl["Residuals", "Sum Sq"]`}{`r cq[1]`}, 
\dfrac{`r aov_tbl["Residuals", "Sum Sq"]`}{`r cq[2]`}
\right] = \left[
`r round(aov_tbl["Residuals", "Sum Sq"]/cq[1], 1)`, 
`r round(aov_tbl["Residuals", "Sum Sq"]/cq[2], 1)`
\right]$$

At **95% confidence level**, we can say that the true error variance $\sigma^2$ lies between the interval (`r round(ci_sigmasq, 1)`).

<h3><a href="images/2011-1b.png" data-fancybox>Exercise: Exam 2011 1(b)</a></h3>
]

---
.left-column[
# ANOVA Model
## Post-hoc Test
```{r, fig.width=3.5, out.width='90%', fig.asp = 1, fig.retina=2}
tky <- TukeyHSD(aov(mdl))
tky_df <- as.data.frame(tky[["Weight1"]]) %>% 
  rownames_to_column("Weight1")
tky_plt <- ggplot(tky_df, 
       aes(Weight1, diff, ymin = lwr, ymax = upr)) +
  geom_point(color = "red") +
  geom_errorbar(width = 0.5) +
  geom_hline(yintercept = 0, color = "royalblue", linetype = 2) +
  geom_label(aes(label = round(diff, 1)), vjust = -0.5) +
  geom_text(aes(label = Weight1), vjust = 1.5) +
  coord_flip() +
  labs(y = "Difference in Weight2") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  ggtitle("Tukey pairwise comparison",
          "95% confidence interval")
tky_plt
```
.side-caption[
Think what will happen if you increase the confidence level from 0.05 to 0.1.
]
].right-column[
### Tukey Pairwise Comparison
For multiple testing, Tukey has suggested **studentized range statistic** as,
$$q = 
\dfrac{\bar{y}_\text{max} - \bar{y}_\text{max}}
{\sqrt{\text{MSE}/n}}$$
Compare $q$ with $q_\alpha(a, f)$ found in <a href="images/qtable005.png" data-fancybox="gallery">table</a><a href="images/qtable001.png" data-fancybox="gallery"></a>. We declare a pair to be significantly different if $q > q_{\alpha}(a, f)$.

### Confidence Interval
$$(\bar{y}_i - \bar{y}_j) \pm q_\alpha(a, f)\sqrt{\frac{\text{MSE}}{n}}$$
$$(\bar{y}_i - \bar{y}_j) - q_\alpha(a, f)\sqrt{\frac{\text{MSE}}{n}} \le \mu_i - \mu_j \le (\bar{y}_i - \bar{y}_j) + q_\alpha(a, f)\sqrt{\frac{\text{MSE}}{n}}$$
You can also check if this interval contains zero.
]

---

.left-column[
# ANOVA Model
## Post-hoc Example
```{r, fig.width=3.5, out.width='90%', fig.asp = 0.9, fig.retina=2}
tky_plt
```

```{r}
print(as.data.frame(wt_sumry[, -3]), row.names = FALSE)
```

].right-column[
<h3><a href = "images/2013-2.png" data-fancybox="gallery">Exam 2013, 2(d)</a></h3>

From the <a href="images/2013-a1.png" data-fancybox="gallery">Appendix 1</a> and <a href="images/2013-a4.png" data-fancybox="gallery">Appendix 4</a>, we have,

```{r}
as.data.frame(aov_tbl)
```

Using <a href="images/qtable005.png" data-fancybox="gallery">studentized, T-distribution table</a> $q_{0.05}(3, 21) = `r qtukey(0.05, 3, 21, lower.tail = FALSE)`$. So,

$$T_{0.05} = q_{0.05}(3, 21)\sqrt{\frac{`r aov_tbl["Residuals", "Mean Sq"]`}{`r as.numeric(wt_sumry[1, "n"])`}} = `r qtukey(0.05, 3, 21, lower.tail = FALSE) * sqrt(aov_tbl["Residuals", "Mean Sq"]/wt_sumry[1, "n"])`$$

We have three possible pairs for comparison: `Low-High`, `Medium-High` and `Medium-Low`. The difference in their means are: <code>`r apply(combn(wt_sumry$mean, 2), 2, diff)`</code> respectively. 

If compared with $T_{0.05}(3, 21)$, we see that at 95% confidence level, we find `Low-High` and `Medium-Low` differ significantly.

<h3><a href="pastexams/2013.pdf" target = "_blank">Exam 2015, 1(e)</a></h3>
]

---

.left-column[
# ANOVA Model
## Contrast test
```{r, fig.width=3.5, out.width='90%', fig.asp = 0.9, fig.retina=2}
get_tplot(0.025, 21, 3, c(1.94, -1.94))
```
].right-column[
### Use cases

- Comparison of one group with average of other group
- Comparing treatments with control

<h3><a href="images/2014-2d.png" data-fancybox>Exam 2014: 2(d)</a></h3>
**Hypothesis:**
$$H_0: \frac{1}{2}(\mu_1 + \mu_2) - \frac{1}{2}(\mu_3 + \mu_4) = 0 \text{ vs }
H_1: \frac{1}{2}(\mu_1 + \mu_2)- \frac{1}{2}(\mu_3 + \mu_4) \ne 0$$

**Decision:**

From <a href="images/2014-a8.png" data-fancybox>Table 8</a>, $\text{p-value }(0.065) > 0.05$.
<details>
<summary><em>What should we conclude?</em></summary>
.small[
At 5% significance level we reject null hypothesis. So, we can not argue that expected differs significantly between January-June and July-December.
]
</details>
]

---

.left-column[
# ANOVA Model
## Contrast Calculation
```{r, fig.width=3.5, out.width='90%', fig.asp = 0.9, fig.retina=2}
get_tplot(0.025, 21, 3, c(1.94, -1.94))
```
Continue on Exam 2014: 2(d)
].right-column[
Before any compution, **formulate a hypothesis**.

### Estimate of Contrast
$$\Gamma = \sum_{i = 1}^a{c_i\mu_i} = \frac{1}{2}(\mu_1 + \mu_2) - \frac{1}{2}(\mu_3 - \mu_4) = -5.5$$
Here the contrast coefficients $c_i$ are: $1/2, 1/2, -1/2, -1/2$. Contrast coefficients sum to zero. For estimation of $\Gamma$, use respective sample mean. Also use <a href="images/2014-a6.png" data-fancybox>Table 6</a> for following calculations.

### Standard Error and test statistic
\begin{aligned}
\text{SE}(\hat{\Gamma}) = \sqrt{\frac{\text{MSE}}{n}\sum_{i = 1}^a{c_i^2}} = 2.82 && 
t = \frac{\hat{\Gamma}}{\text{S.E}(\hat{\Gamma})} \sim t_{\alpha/2, N-a}
\end{aligned}
]

---

.left-column[
# ANOVA Model
## Random Effect Model
### Random factor
$$\tau_i \sim \mathrm{N}(0, \sigma_\tau^2)$$
### Fixed factor
$$\sum_{i = 1}^a{\tau_i} = 0$$
].right-column[
### The Model
$$y_{ij} = \mu + \tau_i + \varepsilon_{ij} \text{ where, } \varepsilon_{ij} \sim \mathrm{N}(0, \sigma^2)\text{ and } \tau_i \sim \mathrm{N}(0, \sigma^2_\tau)$$

### Why Random effect model
_Specific levels are not of interest_. General variation is more important. Levels of a factor are **randomly selected**. For example, if `besetning` (farm) is not of interest, we randomly sample such farms from a population of farm.

Usually, **blocks** are taken as random factor.

### A comparison with Fixed Effect Model
_Specific levels of a factor is important_ than their general variation. These levels are **specifically chosen**. For instance, comparison of new and old drug where a particular drug is used for comparison.
]

---

.left-column[
# ANOVA Model
## Random Effect Model

```{r, fig.width=3.5, out.width='90%', fig.asp = 0.9, fig.retina=2}
get_fplot(0.05, c(5, 18), 7, 1.74)
```
].right-column[
<h3><a href="images/2011-1a.png" data-fancybox="gallery">Exam 2011: 1(a)</a></h3>
**Hypothesis:**
$$H_0: \sigma_\tau^2 = 0 \text{ vs } H_1: \sigma_\tau^2 > 0$$
From <a href="images/2011-a2.png" data-fancybox="gallery">Appendix 2</a>, we see p-value is larger than $\alpha = 0.05$, we can not reject the null hypothesis. So, we claim that **at 95% confidence level** we claim that there is _not significant variation_ between the farms.

### Estimates of Variance Components
$$\text{total variation var}(y_{ij}) = \sigma_\tau^2 + \sigma^2$$
We estimate them as,
$$\hat{\sigma} = \text{MSE} \text{ and } \hat{\sigma_\tau} = \frac{\text{MS}_\text{treatment} - \text{MSE}}{n}$$
]

---

.left-column[
# ANOVA Model
## Random Effect Model

- <a href="images/2011-1cd.png" data-fancybox>Exam 2011: 1(c), 1(d)</a>
- <a href="images/2012-1c.png" data-fancybox>Exam 2012: 1(c)</a>
- <a href="images/2013-1c.png" data-fancybox>Exam 2013: 1(c)</a>
- <a href="images/2014-1e.png" data-fancybox>Exam 2014: 1(e)</a>
- <a href="images/2015-2c.png" data-fancybox>Exam 2015: 2(c)</a>

].right-column[
### Intraclass Correlation Coefficient
Proportion of variation between groups to total variation.
$$\rho = \frac{\sigma_\tau^2}{\sigma_\tau^2 + \sigma^2}$$
Using estimates of variance components, we can estimate intraclass correlation coefficient.

### Confidence interval of overall mean
The $100(1-\alpha)$ level of confidence interval for overall mean $\mu$ in case of **random effect model** is,
$$\hat{\mu} \pm t_{\alpha/2, N-a}\sqrt{\frac{\text{MS}_\text{treatment}}{N}}$$
]
